trainer: imgrec_trainer_lainr_constant
warmup_epochs: 0
train_dataset:
  name: imgrec_dataset
  args:
    imageset:
      name: celebahq_sr
      args: {root_path: /home/idies/.cache/kagglehub/datasets/lamsimon/celebahq/versions/1/, split: train}
    resize: 64
  loader:
    batch_size: 8
    num_workers: 8

test_dataset:
  name: imgrec_dataset
  args:
    imageset:
      name: celebahq_sr
      args: {root_path: /home/idies/.cache/kagglehub/datasets/lamsimon/celebahq/versions/1/, split: test}
    resize: 64
  loader:
    batch_size: 8
    num_workers: 8

model:
  name: lainr_inr
  args:
    tokenizer:
      name: mamba_patch_tokenizer
      args: {input_size: 64, patch_size: 1, dim: 256, pos_emb: 'fourier'}
    hyponet:
      name: lainr_mlp
      args: {feature_dim: 256, input_dim: 2, output_dim: 3, sigma_q: 16, sigma_ls: [128, 32]}
    transformer_encoder:
      name: transformer_encoder
      args: {dim: 256, depth: 6, ff_dim: 1024, n_head: 12, head_dim: 64}
    num_lp: 256

optimizer:
  name: adamw
  args: {lr: 1.e-4}
max_epoch: 200

eval_epoch: 1
vis_epoch: 5
