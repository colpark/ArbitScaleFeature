{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7994684e-06b5-48e8-886e-b3b3a91e3b47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T15:42:45.456350Z",
     "iopub.status.busy": "2025-07-03T15:42:45.455993Z",
     "iopub.status.idle": "2025-07-03T15:42:45.460964Z",
     "shell.execute_reply": "2025-07-03T15:42:45.460441Z",
     "shell.execute_reply.started": "2025-07-03T15:42:45.456326Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import os\n",
    "from einops import rearrange, repeat\n",
    "import einops\n",
    "from glob import glob\n",
    "from math import log\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "#from staf import StafLayer\n",
    "    #from staf import INR\n",
    "from mamba_ssm import Mamba\n",
    "from mamba_ssm.modules.block import Block\n",
    "import matplotlib.pyplot as plt\n",
    "from transformer import TransformerEncoderINR\n",
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import cProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a095377-b677-4d5c-ba10-d609768ffd78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T15:38:00.805329Z",
     "iopub.status.busy": "2025-07-03T15:38:00.804943Z",
     "iopub.status.idle": "2025-07-03T15:38:00.808097Z",
     "shell.execute_reply": "2025-07-03T15:38:00.807540Z",
     "shell.execute_reply.started": "2025-07-03T15:38:00.805309Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5603fe5-ef63-401c-b6a0-e1d6aad35d37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T15:38:07.266599Z",
     "iopub.status.busy": "2025-07-03T15:38:07.266279Z",
     "iopub.status.idle": "2025-07-03T15:38:07.279538Z",
     "shell.execute_reply": "2025-07-03T15:38:07.279082Z",
     "shell.execute_reply.started": "2025-07-03T15:38:07.266577Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BiMamba(torch.nn.Module):\n",
    "    def __init__(self, dim = 512):\n",
    "        super(BiMamba, self).__init__()\n",
    "        \n",
    "        self.f_mamba = Mamba(d_model = dim)\n",
    "        self.r_mamba = Mamba(d_model = dim)\n",
    "        \n",
    "    def forward(self, x, **kwargs):\n",
    "        x_f = self.f_mamba(x, **kwargs)\n",
    "        x_r = torch.flip(self.r_mamba(torch.flip(x, dims=[1]), **kwargs), dims=[1])\n",
    "        out = (x_f + x_r)/2\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class MambaINRModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, token_dim = 512, output_size = 3, model_type = 'stacked'):\n",
    "        super(MambaINRModel, self).__init__()\n",
    "        if model_type == 'stacked':\n",
    "            self.mamba = MambaStack(num = 6, token_dim = token_dim)\n",
    "        else:\n",
    "            self.mamba = BiMamba(token_dim = token_dim)\n",
    "            \n",
    "        self.input = torch.nn.Linear(input_size, token_dim)\n",
    "        self.output = torch.nn.Linear(token_dim, output_size)\n",
    "        torch.nn.Linear(token_dim, output_size)\n",
    "        self.sig = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = self.mamba(x)\n",
    "        x = self.output(x)\n",
    "        x = self.sig(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class MambaCLS(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, token_dim = 512, output_size = 3, model_type = 'stacked', num_lp = 1):\n",
    "        super(MambaCLS, self).__init__()\n",
    "        self.token_dim = token_dim\n",
    "        if model_type == 'stacked':\n",
    "            self.mamba = MambaStack(num = 6, token_dim = self.token_dim)\n",
    "        else:\n",
    "            self.mamba = BiMamba(token_dim = self.token_dim)\n",
    "            \n",
    "        self.input = torch.nn.Linear(input_size, self.token_dim)\n",
    "        self.output = torch.nn.Linear(self.token_dim, output_size)\n",
    "        self.pred_out= torch.nn.Sequential(torch.nn.Linear(self.token_dim, 2*self.token_dim), torch.nn.Linear(2*self.token_dim, 2*self.token_dim),\n",
    "                                               torch.nn.Linear(2*self.token_dim, output_size))\n",
    "\n",
    "        self.sig = torch.nn.Sigmoid()\n",
    "\n",
    "        self.num_lp = num_lp\n",
    "        self.lp = torch.nn.Parameter(torch.empty((self.num_lp, self.token_dim), dtype = torch.float32))\n",
    "        \n",
    "        self.lp_idxs = None\n",
    "    \n",
    "    def set_lp_idxs(self, lp_idxs):\n",
    "        self.lp_idxs = lp_idxs\n",
    "        \n",
    "    def add_lp(self, x):\n",
    "        \n",
    "        if x.ndim == 2:\n",
    "            seq_len = x.shape[0]\n",
    "        elif x.ndim == 3:\n",
    "            seq_len = x.shape[1]\n",
    "        total_len = seq_len + self.num_lp\n",
    "        \n",
    "        chunk_size = round(seq_len/(self.num_lp+1))\n",
    "        insert_idxs = torch.clamp(torch.tensor([(chunk_size+1)*(x+1)-1 for x in range (self.num_lp)]), min = 0, max = total_len-1)\n",
    "        self.set_lp_idxs(insert_idxs)\n",
    "        \n",
    "\n",
    "        mask = torch.zeros(total_len, dtype=torch.bool)\n",
    "        mask[insert_idxs] = True\n",
    "\n",
    "        out = torch.empty((x.shape[0], total_len, self.token_dim), dtype=torch.float32).to(x.device)\n",
    "        out[:, mask] = self.lp\n",
    "        out[:, ~mask] = x\n",
    "        return out\n",
    "    \n",
    "    def extract_lp_tokens(self, x):\n",
    "        return x[:, self.lp_idxs]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.input(x)\n",
    "        #print(x.shape)\n",
    "        x = self.add_lp(x)\n",
    "        #print(x.shape)\n",
    "        x = self.mamba(x)\n",
    "        #print(x.shape)\n",
    "        #x = self.output(x)\n",
    "        x = self.extract_lp_tokens(x)\n",
    "        x = self.pred_out(x.squeeze(1))\n",
    "\n",
    "        return x\n",
    "\n",
    "class MambaStack(torch.nn.Module):\n",
    "    def __init__(self, num = 3, token_dim = 512):\n",
    "        super(MambaStack, self).__init__()\n",
    "        self.blocks = nn.ModuleList([\n",
    "            Block(\n",
    "                dim=token_dim,\n",
    "                mixer_cls= lambda dim: BiMamba(dim),\n",
    "                mlp_cls= lambda dim: torch.nn.Sequential(\n",
    "                    nn.Linear(dim, 4 * dim),\n",
    "                    nn.GELU(),\n",
    "                    nn.Linear(4 * dim, dim),\n",
    "                ),\n",
    "                norm_cls=nn.LayerNorm,  # or RMSNorm\n",
    "                fused_add_norm=False\n",
    "            )\n",
    "            for _ in range(num)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = None\n",
    "        for block in self.blocks:\n",
    "            x, residual = block(x, residual=residual)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb49cd6-867e-4eec-950e-049439a211b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T15:38:10.029450Z",
     "iopub.status.busy": "2025-07-03T15:38:10.029112Z",
     "iopub.status.idle": "2025-07-03T15:38:10.035590Z",
     "shell.execute_reply": "2025-07-03T15:38:10.035137Z",
     "shell.execute_reply.started": "2025-07-03T15:38:10.029428Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2638, -0.8965,  0.1289,  0.1090, -1.1527]])\n",
      "tensor([[[-0.2638],\n",
      "         [-0.8965],\n",
      "         [ 0.1289],\n",
      "         [ 0.1090],\n",
      "         [-1.1527]]])\n"
     ]
    }
   ],
   "source": [
    "test_input = torch.randn((1, 5))\n",
    "print(test_input)\n",
    "test_input = test_input.unsqueeze(2)\n",
    "print(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b4f7b7b-5135-4418-a2f9-d3158853e5df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T15:38:11.215140Z",
     "iopub.status.busy": "2025-07-03T15:38:11.214775Z",
     "iopub.status.idle": "2025-07-03T15:38:11.748714Z",
     "shell.execute_reply": "2025-07-03T15:38:11.748126Z",
     "shell.execute_reply.started": "2025-07-03T15:38:11.215119Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 784, 1])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "model = MambaCLS(input_size = 1, output_size = 10).to(device)\n",
    "model.eval()\n",
    "\n",
    "test_input = torch.randn((1, 28*28)).unsqueeze(2).to(device)\n",
    "print(test_input.shape)\n",
    "out = model(test_input)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3159a4f9-021d-429a-afbc-34bbb7175898",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T15:38:12.904371Z",
     "iopub.status.busy": "2025-07-03T15:38:12.904005Z",
     "iopub.status.idle": "2025-07-03T15:38:12.907289Z",
     "shell.execute_reply": "2025-07-03T15:38:12.906786Z",
     "shell.execute_reply.started": "2025-07-03T15:38:12.904346Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_epochs = 5\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c26231b-4e36-49d4-9a15-29622c330775",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T15:38:13.710344Z",
     "iopub.status.busy": "2025-07-03T15:38:13.709988Z",
     "iopub.status.idle": "2025-07-03T15:38:13.764642Z",
     "shell.execute_reply": "2025-07-03T15:38:13.764138Z",
     "shell.execute_reply.started": "2025-07-03T15:38:13.710322Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_data = datasets.FashionMNIST(root='.', train=True, download=True, transform=transform)\n",
    "test_data = datasets.FashionMNIST(root='.', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5f5e61f-9616-4b96-9873-e0cba5e54a9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T15:38:15.032194Z",
     "iopub.status.busy": "2025-07-03T15:38:15.031855Z",
     "iopub.status.idle": "2025-07-03T15:38:15.036158Z",
     "shell.execute_reply": "2025-07-03T15:38:15.035683Z",
     "shell.execute_reply.started": "2025-07-03T15:38:15.032171Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  6,  2,  7,  3,  8,  4,  9,  5, 10]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]]])\n",
    "x = torch.transpose(x, 1, 2)\n",
    "print(x.reshape(1, 10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b17c4d6-a589-4fec-a015-33ea81337364",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T15:38:16.256934Z",
     "iopub.status.busy": "2025-07-03T15:38:16.256573Z",
     "iopub.status.idle": "2025-07-03T15:38:16.259962Z",
     "shell.execute_reply": "2025-07-03T15:38:16.259460Z",
     "shell.execute_reply.started": "2025-07-03T15:38:16.256910Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scan(x):\n",
    "    return x.reshape(x.shape[0], -1).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "344b1a2d-1a34-4f7e-aed9-384ba435a9da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T15:47:53.182285Z",
     "iopub.status.busy": "2025-07-03T15:47:53.181940Z",
     "iopub.status.idle": "2025-07-03T15:47:53.188448Z",
     "shell.execute_reply": "2025-07-03T15:47:53.187796Z",
     "shell.execute_reply.started": "2025-07-03T15:47:53.182264Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "    # ======= Model Setup =======\n",
    "    model_dim = 128\n",
    "    num_classes = 10\n",
    "\n",
    "    model = MambaCLS(input_size = 1, output_size = num_classes).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # ======= Training Loop =======\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for imgs, labels in tqdm(train_loader):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            #x = patchify(imgs, patch_size)  # (B, N, D)\n",
    "            x = scan(imgs)\n",
    "            preds = model(x)\n",
    "            loss = criterion(preds, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}] Train Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # Eval\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in tqdm(test_loader):\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                x = scan(imgs)\n",
    "                preds = model(x)\n",
    "                pred_labels = preds.argmax(dim=1)\n",
    "                correct += (pred_labels == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        acc = correct / total\n",
    "        print(f\"[Epoch {epoch+1}] Test Accuracy: {acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc789f84-7a69-4919-aac4-575cc9621723",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T15:47:55.385056Z",
     "iopub.status.busy": "2025-07-03T15:47:55.384700Z",
     "iopub.status.idle": "2025-07-03T15:49:00.464113Z",
     "shell.execute_reply": "2025-07-03T15:49:00.463354Z",
     "shell.execute_reply.started": "2025-07-03T15:47:55.385032Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 48/938 [01:04<19:59,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         816651 function calls (802132 primitive calls) in 64.978 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000   64.978   64.978 {built-in method builtins.exec}\n",
      "        1    0.000    0.000   64.978   64.978 <string>:1(<module>)\n",
      "        1    0.021    0.021   64.978   64.978 3215347763.py:1(train)\n",
      "       49    0.001    0.000   43.678    0.891 _tensor.py:592(backward)\n",
      "       49    0.001    0.000   43.677    0.891 __init__.py:243(backward)\n",
      "       49    0.001    0.000   43.672    0.891 graph.py:815(_engine_run_backward)\n",
      "       49   43.671    0.891   43.671    0.891 {method 'run_backward' of 'torch._C._EngineBase' objects}\n",
      "8820/3234    0.017    0.000   20.136    0.006 module.py:1747(_wrapped_call_impl)\n",
      "8820/3234    0.028    0.000   20.130    0.006 module.py:1755(_call_impl)\n",
      "       49    0.002    0.000   19.894    0.406 3962538750.py:86(forward)\n",
      "       49   18.246    0.372   18.246    0.372 3962538750.py:83(extract_lp_tokens)\n",
      "     4038    1.082    0.000    1.082    0.000 {method 'to' of 'torch._C.TensorBase' objects}\n",
      "       49    0.016    0.000    1.029    0.021 3962538750.py:62(add_lp)\n",
      "       50    0.001    0.000    0.789    0.016 std.py:1160(__iter__)\n",
      "       49    0.001    0.000    0.744    0.015 dataloader.py:728(__next__)\n",
      "       49    0.002    0.000    0.737    0.015 dataloader.py:787(_next_data)\n",
      "       49    0.000    0.000    0.730    0.015 fetch.py:47(fetch)\n",
      "       49    0.003    0.000    0.720    0.015 fetch.py:52(<listcomp>)\n",
      "     3136    0.055    0.000    0.716    0.000 mnist.py:131(__getitem__)\n",
      "       49    0.003    0.000    0.595    0.012 3962538750.py:118(forward)\n",
      "      294    0.015    0.000    0.589    0.002 block.py:42(forward)\n",
      "     3136    0.009    0.000    0.556    0.000 transforms.py:93(__call__)\n",
      "      294    0.014    0.000    0.490    0.002 3962538750.py:8(forward)\n",
      "      588    0.076    0.000    0.458    0.001 mamba_simple.py:119(forward)\n",
      "     3136    0.009    0.000    0.310    0.000 transforms.py:129(__call__)\n",
      "     3136    0.042    0.000    0.302    0.000 functional.py:127(to_tensor)\n",
      "        1    0.000    0.000    0.247    0.247 3962538750.py:39(__init__)\n",
      "        1    0.000    0.000    0.236    0.236 3962538750.py:101(__init__)\n",
      "        1    0.000    0.000    0.236    0.236 3962538750.py:103(<listcomp>)\n",
      "        6    0.000    0.000    0.236    0.039 block.py:11(__init__)\n",
      "       65    0.000    0.000    0.230    0.004 linear.py:93(__init__)\n",
      "       65    0.000    0.000    0.226    0.003 linear.py:114(reset_parameters)\n",
      "      130    0.225    0.002    0.225    0.002 {method 'uniform_' of 'torch._C.TensorBase' objects}\n",
      "       77    0.001    0.000    0.225    0.003 init.py:456(kaiming_uniform_)\n",
      "     3136    0.004    0.000    0.219    0.000 transforms.py:269(forward)\n",
      "     3136    0.015    0.000    0.216    0.000 functional.py:327(normalize)\n",
      "       48    0.002    0.000    0.192    0.004 optimizer.py:465(wrapper)\n",
      "     3136    0.063    0.000    0.184    0.000 _functional_tensor.py:905(normalize)\n",
      "       48    0.002    0.000    0.182    0.004 optimizer.py:60(_use_grad)\n",
      "       48    0.001    0.000    0.180    0.004 adam.py:212(step)\n",
      "        6    0.000    0.000    0.156    0.026 3962538750.py:106(<lambda>)\n",
      "        6    0.000    0.000    0.156    0.026 3962538750.py:2(__init__)\n",
      "       12    0.002    0.000    0.155    0.013 mamba_simple.py:32(__init__)\n",
      "     5292    0.006    0.000    0.132    0.000 einops.py:545(rearrange)\n",
      "     5304    0.024    0.000    0.126    0.000 einops.py:460(reduce)\n",
      "       48    0.000    0.000    0.121    0.003 optimizer.py:130(maybe_fallback)\n",
      "       48    0.007    0.000    0.121    0.003 adam.py:865(adam)\n",
      "     3136    0.030    0.000    0.113    0.000 {built-in method numpy.array}\n",
      "     1960    0.006    0.000    0.109    0.000 linear.py:124(forward)\n",
      "       48    0.002    0.000    0.103    0.002 adam.py:534(_multi_tensor_adam)\n",
      "     1960    0.101    0.000    0.101    0.000 {built-in method torch._C._nn.linear}\n",
      "     5304    0.017    0.000    0.090    0.000 einops.py:230(_apply_recipe)\n",
      "     3136    0.025    0.000    0.088    0.000 Image.py:3257(fromarray)\n",
      "     3136    0.007    0.000    0.082    0.000 Image.py:747(__array_interface__)\n",
      "        6    0.000    0.000    0.078    0.013 3962538750.py:107(<lambda>)\n",
      "    15890    0.078    0.000    0.078    0.000 {method 'item' of 'torch._C.TensorBase' objects}\n",
      "      588    0.001    0.000    0.075    0.000 selective_scan_interface.py:106(selective_scan_fn)\n",
      "      588    0.004    0.000    0.074    0.000 function.py:559(apply)\n",
      "     3136    0.021    0.000    0.063    0.000 Image.py:775(tobytes)\n",
      "     3136    0.010    0.000    0.062    0.000 Image.py:3185(frombuffer)\n",
      "      343    0.002    0.000    0.062    0.000 container.py:238(forward)\n",
      "      588    0.015    0.000    0.061    0.000 {built-in method apply}\n",
      "       48    0.031    0.001    0.055    0.001 adam.py:137(_init_group)\n",
      "      588    0.016    0.000    0.046    0.000 selective_scan_interface.py:25(forward)\n",
      "        1    0.000    0.000    0.043    0.043 module.py:1228(to)\n",
      "    142/1    0.004    0.000    0.043    0.043 module.py:912(_apply)\n",
      "     4704    0.003    0.000    0.042    0.000 _backends.py:92(reshape)\n",
      "       48    0.001    0.000    0.042    0.001 std.py:1198(update)\n",
      "       50    0.000    0.000    0.042    0.001 std.py:1464(display)\n",
      "       49    0.000    0.000    0.042    0.001 std.py:1325(refresh)\n",
      "     6272    0.041    0.000    0.041    0.000 {built-in method torch.as_tensor}\n",
      "     4753    0.040    0.000    0.040    0.000 {method 'reshape' of 'torch._C.TensorBase' objects}\n",
      "     7252    0.039    0.000    0.039    0.000 {method 'permute' of 'torch._C.TensorBase' objects}\n",
      "      588    0.002    0.000    0.038    0.000 conv.py:374(forward)\n",
      "      167    0.000    0.000    0.037    0.000 module.py:1332(convert)\n",
      "      588    0.001    0.000    0.035    0.000 conv.py:357(_conv_forward)\n",
      "       50    0.000    0.000    0.035    0.001 std.py:457(print_status)\n",
      "      588    0.034    0.000    0.034    0.000 {built-in method torch.conv1d}\n",
      "     3136    0.034    0.000    0.034    0.000 {method 'div' of 'torch._C.TensorBase' objects}\n",
      "     3136    0.009    0.000    0.033    0.000 Image.py:3087(new)\n",
      "       50    0.000    0.000    0.033    0.001 std.py:451(fp_write)\n",
      "      102    0.000    0.000    0.033    0.000 utils.py:194(inner)\n",
      "     9408    0.032    0.000    0.032    0.000 {method 'view' of 'torch._C.TensorBase' objects}\n",
      "    15840    0.015    0.000    0.030    0.000 optimizer.py:89(_get_value)\n",
      "       52    0.001    0.000    0.029    0.001 iostream.py:592(flush)\n",
      "       50    0.000    0.000    0.027    0.001 _compile.py:41(inner)\n",
      "       50    0.001    0.000    0.026    0.001 eval_frame.py:829(_fn)\n",
      "       52    0.000    0.000    0.026    0.001 threading.py:589(wait)\n",
      "     4116    0.002    0.000    0.026    0.000 _backends.py:257(transpose)\n",
      "       52    0.000    0.000    0.026    0.001 threading.py:288(wait)\n",
      "      415    0.026    0.000    0.026    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "       49    0.018    0.000    0.025    0.001 optimizer.py:931(zero_grad)\n",
      "     6272    0.014    0.000    0.025    0.000 utils.py:627(_log_api_usage_once)\n",
      "     4912    0.024    0.000    0.024    0.000 {method 'contiguous' of 'torch._C.TensorBase' objects}\n",
      "      588    0.002    0.000    0.023    0.000 normalization.py:216(forward)\n",
      "      588    0.003    0.000    0.021    0.000 functional.py:2889(layer_norm)\n",
      "     6272    0.013    0.000    0.019    0.000 Image.py:587(_new)\n",
      "       48    0.003    0.000    0.019    0.000 adam.py:738(<listcomp>)\n",
      "       48    0.018    0.000    0.018    0.000 {built-in method torch._foreach_sqrt}\n",
      "     3136    0.018    0.000    0.018    0.000 {method 'numpy' of 'torch._C.TensorBase' objects}\n",
      "      588    0.017    0.000    0.017    0.000 {built-in method torch.layer_norm}\n",
      "       48    0.003    0.000    0.017    0.000 adam.py:741(<listcomp>)\n",
      "     3136    0.017    0.000    0.017    0.000 {method 'any' of 'torch._C.TensorBase' objects}\n",
      "    18631    0.016    0.000    0.016    0.000 module.py:1927(__getattr__)\n",
      "86745/85365    0.014    0.000    0.016    0.000 {built-in method builtins.isinstance}\n",
      "     3136    0.016    0.000    0.016    0.000 {method 'clone' of 'torch._C.TensorBase' objects}\n",
      "     3136    0.011    0.000    0.015    0.000 Image.py:445(_getencoder)\n",
      "     3136    0.015    0.000    0.015    0.000 {method 'sub_' of 'torch._C.TensorBase' objects}\n",
      "      588    0.001    0.000    0.014    0.000 activation.py:431(forward)\n",
      "      588    0.001    0.000    0.014    0.000 functional.py:170(split)\n",
      "    42953    0.013    0.000    0.013    0.000 {method 'append' of 'list' objects}\n",
      "      588    0.013    0.000    0.013    0.000 {built-in method selective_scan_cuda.fwd}\n",
      "      588    0.001    0.000    0.013    0.000 functional.py:2358(silu)\n",
      "      588    0.004    0.000    0.013    0.000 _tensor.py:1038(split)\n",
      "      588    0.013    0.000    0.013    0.000 {built-in method torch.flip}\n",
      "      145    0.002    0.000    0.012    0.000 {built-in method builtins.all}\n",
      "      600    0.012    0.000    0.012    0.000 {built-in method torch.exp}\n",
      "      588    0.012    0.000    0.012    0.000 {built-in method torch._C._nn.silu}\n",
      "     3136    0.007    0.000    0.011    0.000 Image.py:250(_conv_type_shape)\n",
      "     3136    0.011    0.000    0.011    0.000 {built-in method torch.from_numpy}\n",
      "     3136    0.011    0.000    0.011    0.000 {method 'div_' of 'torch._C.TensorBase' objects}\n",
      "     3136    0.005    0.000    0.011    0.000 _functional_pil.py:41(get_image_num_channels)\n",
      "       48    0.000    0.000    0.010    0.000 optimizer.py:499(_group_tensors_by_device_and_dtype)\n",
      "       48    0.000    0.000    0.010    0.000 _contextlib.py:113(decorate_context)\n",
      "      146    0.002    0.000    0.010    0.000 profiler.py:776(__exit__)\n",
      "       96    0.010    0.000    0.010    0.000 {built-in method torch._foreach_add_}\n",
      "       49    0.000    0.000    0.010    0.000 collate.py:337(default_collate)\n",
      "   147/49    0.001    0.000    0.010    0.000 collate.py:118(collate)\n",
      "     6272    0.005    0.000    0.010    0.000 _trace.py:1324(is_tracing)\n",
      "     8823    0.009    0.000    0.009    0.000 {built-in method torch._C._get_tracing_state}\n",
      "      146    0.001    0.000    0.009    0.000 profiler.py:770(__enter__)\n",
      "       48    0.000    0.000    0.009    0.000 _foreach_utils.py:32(_group_tensors_by_device_and_dtype)\n",
      "       48    0.009    0.000    0.009    0.000 {built-in method torch._C._group_tensors_by_device_and_dtype}\n",
      "      588    0.009    0.000    0.009    0.000 {method 'chunk' of 'torch._C.TensorBase' objects}\n",
      "      146    0.000    0.000    0.009    0.000 _ops.py:981(__call__)\n",
      "      588    0.002    0.000    0.009    0.000 utils.py:32(unwrap_dead_wrappers)\n",
      "     3136    0.008    0.000    0.008    0.000 {method 'encode' of 'ImagingEncoder' objects}\n",
      "       48    0.000    0.000    0.008    0.000 optimizer.py:160(_default_to_fused_or_foreach)\n",
      "      146    0.000    0.000    0.008    0.000 _ops.py:1147(__call__)\n",
      "      146    0.008    0.000    0.008    0.000 {built-in method torch._ops.profiler._record_function_enter_new}\n",
      "       48    0.008    0.000    0.008    0.000 {built-in method torch._foreach_addcdiv_}\n",
      "     6272    0.006    0.000    0.007    0.000 Image.py:3068(_check_size)\n",
      "     6416    0.007    0.000    0.007    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "      588    0.007    0.000    0.007    0.000 {built-in method torch.split_with_sizes}\n",
      "     3136    0.004    0.000    0.007    0.000 Image.py:891(load)\n",
      "     9408    0.007    0.000    0.007    0.000 Image.py:549(__init__)\n",
      "50165/50158    0.007    0.000    0.007    0.000 {built-in method builtins.len}\n",
      "       50    0.000    0.000    0.007    0.000 std.py:1150(__str__)\n",
      "     6468    0.003    0.000    0.007    0.000 utils.py:34(<genexpr>)\n",
      "     7968    0.007    0.000    0.007    0.000 optimizer.py:177(<genexpr>)\n",
      "      914    0.002    0.000    0.006    0.000 module.py:1944(__setattr__)\n",
      "    16176    0.005    0.000    0.006    0.000 __init__.py:380(is_compiling)\n",
      "      146    0.001    0.000    0.006    0.000 _ops.py:1035(_must_dispatch_in_python)\n",
      "     3136    0.006    0.000    0.006    0.000 {built-in method PIL._imaging.fill}\n",
      "       49    0.000    0.000    0.006    0.000 collate.py:211(<listcomp>)\n",
      "      294    0.000    0.000    0.006    0.000 activation.py:733(forward)\n",
      "       50    0.004    0.000    0.006    0.000 std.py:464(format_meter)\n",
      "      146    0.000    0.000    0.006    0.000 _pytree.py:1410(tree_any)\n",
      "     3136    0.006    0.000    0.006    0.000 {built-in method PIL._imaging.map_buffer}\n",
      "     3137    0.001    0.000    0.006    0.000 sampler.py:167(__iter__)\n",
      "       49    0.000    0.000    0.006    0.000 dataloader.py:722(_next_index)\n",
      "      294    0.006    0.000    0.006    0.000 {built-in method torch._C._nn.gelu}\n",
      "       98    0.000    0.000    0.006    0.000 {built-in method builtins.next}\n",
      "       50    0.001    0.000    0.006    0.000 sampler.py:326(__iter__)\n",
      "      146    0.000    0.000    0.005    0.000 {built-in method builtins.any}\n",
      "     5304    0.004    0.000    0.005    0.000 _backends.py:22(get_backend)\n",
      "    10608    0.005    0.000    0.005    0.000 _backends.py:88(shape)\n",
      "      311    0.005    0.000    0.005    0.000 {built-in method torch.tensor}\n",
      " 1022/292    0.002    0.000    0.005    0.000 _pytree.py:1071(tree_iter)\n",
      "       49    0.001    0.000    0.005    0.000 collate.py:243(collate_tensor_fn)\n",
      "    45279    0.004    0.000    0.004    0.000 _jit_internal.py:101(is_scripting)\n",
      "       48    0.004    0.000    0.004    0.000 {built-in method torch._foreach_lerp_}\n",
      "       49    0.000    0.000    0.004    0.000 loss.py:1296(forward)\n",
      "     6272    0.003    0.000    0.004    0.000 Image.py:560(im)\n",
      "     6272    0.003    0.000    0.004    0.000 _functional_pil.py:14(_is_pil_image)\n",
      "       49    0.004    0.000    0.004    0.000 {built-in method torch.stack}\n",
      "      330    0.004    0.000    0.004    0.000 {built-in method torch.zeros_like}\n",
      "       48    0.004    0.000    0.004    0.000 {built-in method torch._foreach_addcmul_}\n",
      "     3136    0.002    0.000    0.004    0.000 _functional_tensor.py:13(_assert_image_tensor)\n",
      "      155    0.001    0.000    0.004    0.000 iostream.py:259(schedule)\n",
      "       49    0.000    0.000    0.004    0.000 functional.py:3404(cross_entropy)\n",
      "       52    0.001    0.000    0.004    0.000 iostream.py:655(write)\n",
      "       48    0.004    0.000    0.004    0.000 {built-in method torch._foreach_div_}\n",
      "       49    0.001    0.000    0.004    0.000 __init__.py:89(_make_grads)\n",
      "     6272    0.003    0.000    0.003    0.000 Image.py:571(width)\n",
      "      194    0.003    0.000    0.003    0.000 {built-in method torch.empty}\n",
      "     6272    0.003    0.000    0.003    0.000 {built-in method torch._C._is_tracing}\n",
      "       48    0.003    0.000    0.003    0.000 {built-in method torch._foreach_mul_}\n",
      "     6272    0.002    0.000    0.003    0.000 Image.py:575(height)\n",
      "       49    0.003    0.000    0.003    0.000 {built-in method torch._C._nn.cross_entropy_loss}\n",
      "    21952    0.003    0.000    0.003    0.000 Image.py:583(mode)\n",
      "       12    0.000    0.000    0.003    0.000 conv.py:321(__init__)\n",
      "    14135    0.003    0.000    0.003    0.000 {method 'get' of 'dict' objects}\n",
      "     7920    0.003    0.000    0.003    0.000 {built-in method torch.is_complex}\n",
      "      588    0.003    0.000    0.003    0.000 {method 't' of 'torch._C.TensorBase' objects}\n",
      "    21952    0.003    0.000    0.003    0.000 Image.py:579(size)\n",
      "       53    0.000    0.000    0.003    0.000 init.py:142(uniform_)\n",
      "       53    0.000    0.000    0.003    0.000 init.py:15(_no_grad_uniform_)\n",
      "       12    0.000    0.000    0.003    0.000 conv.py:86(__init__)\n",
      "     6272    0.003    0.000    0.003    0.000 {method 'startswith' of 'str' objects}\n",
      "       48    0.001    0.000    0.003    0.000 optimizer.py:412(_cuda_graph_capture_health_check)\n",
      "     3136    0.002    0.000    0.003    0.000 Image.py:1393(getbands)\n",
      "     8753    0.002    0.000    0.003    0.000 _tensor.py:1197(__hash__)\n",
      "     3136    0.002    0.000    0.002    0.000 functional.py:117(_is_numpy)\n",
      "        1    0.002    0.002    0.002    0.002 {method 'tolist' of 'torch._C.TensorBase' objects}\n",
      "       52    0.000    0.000    0.002    0.000 iostream.py:577(_schedule_flush)\n",
      "      155    0.002    0.000    0.002    0.000 socket.py:623(send)\n",
      "     3136    0.002    0.000    0.002    0.000 {built-in method PIL._imaging.raw_encoder}\n",
      "     7968    0.002    0.000    0.002    0.000 adam.py:914(<genexpr>)\n",
      "     4704    0.002    0.000    0.002    0.000 {built-in method torch._C._functorch.unwrap_if_dead}\n",
      "     4029    0.002    0.000    0.002    0.000 {built-in method builtins.getattr}\n",
      "      143    0.002    0.000    0.002    0.000 module.py:466(__init__)\n",
      "       24    0.002    0.000    0.002    0.000 {built-in method torch.log}\n",
      "     1764    0.002    0.000    0.002    0.000 {method 'float' of 'torch._C.TensorBase' objects}\n",
      "     3136    0.002    0.000    0.002    0.000 _functional_tensor.py:9(_is_tensor_a_torch_image)\n",
      "     3667    0.002    0.000    0.002    0.000 {built-in method builtins.hasattr}\n",
      "       49    0.002    0.000    0.002    0.000 {built-in method torch.ones_like}\n",
      "       12    0.000    0.000    0.002    0.000 normalization.py:177(__init__)\n",
      "        1    0.002    0.002    0.002    0.002 {built-in method torch.randperm}\n",
      "     3186    0.002    0.000    0.002    0.000 {built-in method builtins.max}\n",
      "      146    0.002    0.000    0.002    0.000 {built-in method torch._ops.profiler.}\n",
      "       50    0.000    0.000    0.002    0.000 utils.py:378(disp_len)\n",
      "      858    0.001    0.000    0.002    0.000 grad_mode.py:184(__init__)\n",
      "      584    0.001    0.000    0.002    0.000 _pytree.py:836(_is_leaf)\n",
      "     3303    0.002    0.000    0.002    0.000 {method 'is_floating_point' of 'torch._C.TensorBase' objects}\n",
      "     3136    0.002    0.000    0.002    0.000 {method 'setimage' of 'ImagingEncoder' objects}\n",
      "      146    0.001    0.000    0.002    0.000 profiler.py:759(__init__)\n",
      "     1022    0.001    0.000    0.002    0.000 _pytree.py:829(_get_node_type)\n",
      "        1    0.000    0.000    0.002    0.002 std.py:952(__init__)\n",
      "       50    0.000    0.000    0.001    0.000 utils.py:374(_text_width)\n",
      "     2940    0.001    0.000    0.001    0.000 {method 'stride' of 'torch._C.TensorBase' objects}\n",
      "     3301    0.001    0.000    0.001    0.000 {built-in method torch.get_default_dtype}\n",
      "     6272    0.001    0.000    0.001    0.000 Image.py:567(im)\n",
      "       50    0.000    0.000    0.001    0.000 {built-in method builtins.sum}\n",
      "       49    0.000    0.000    0.001    0.000 collate.py:304(collate_int_fn)\n",
      "        1    0.000    0.000    0.001    0.001 adam.py:34(__init__)\n",
      "        1    0.000    0.000    0.001    0.001 optimizer.py:341(__init__)\n",
      "       48    0.000    0.000    0.001    0.000 __init__.py:161(is_available)\n",
      "      203    0.001    0.000    0.001    0.000 module.py:574(register_parameter)\n",
      "       49    0.000    0.000    0.001    0.000 3962538750.py:59(set_lp_idxs)\n",
      "     3136    0.001    0.000    0.001    0.000 {method 'pixel_access' of 'ImagingCore' objects}\n",
      "       49    0.000    0.000    0.001    0.000 3793230434.py:1(scan)\n",
      "      381    0.000    0.000    0.001    0.000 grad_mode.py:80(__enter__)\n",
      "     1022    0.001    0.000    0.001    0.000 _pytree.py:818(_is_namedtuple_instance)\n",
      "     6272    0.001    0.000    0.001    0.000 {method 'copy' of 'dict' objects}\n",
      "       12    0.000    0.000    0.001    0.000 conv.py:178(reset_parameters)\n",
      "     3136    0.001    0.000    0.001    0.000 collate.py:206(<genexpr>)\n",
      "        2    0.000    0.000    0.001    0.001 std.py:1265(close)\n",
      "     2432    0.001    0.000    0.001    0.000 utils.py:375(<genexpr>)\n",
      "      747    0.001    0.000    0.001    0.000 parameter.py:10(__instancecheck__)\n",
      "    142/1    0.000    0.000    0.001    0.001 module.py:2836(train)\n",
      "       49    0.001    0.000    0.001    0.000 {method 'squeeze' of 'torch._C.TensorBase' objects}\n",
      "      167    0.000    0.000    0.001    0.000 parameter.py:40(__new__)\n",
      "      381    0.000    0.000    0.001    0.000 grad_mode.py:84(__exit__)\n",
      "     5691    0.001    0.000    0.001    0.000 typing.py:1737(cast)\n",
      "     6221    0.001    0.000    0.001    0.000 {method 'items' of 'dict' objects}\n",
      "       48    0.000    0.000    0.001    0.000 __init__.py:157(_nvml_based_avail)\n",
      "      343    0.001    0.000    0.001    0.000 container.py:230(__iter__)\n",
      "     8755    0.001    0.000    0.001    0.000 {built-in method builtins.id}\n",
      "      168    0.000    0.000    0.001    0.000 module.py:2620(parameters)\n",
      "      167    0.001    0.000    0.001    0.000 {built-in method _make_subclass}\n",
      "       49    0.001    0.000    0.001    0.000 {built-in method torch.clamp}\n",
      "      588    0.001    0.000    0.001    0.000 _VF.py:27(__getattr__)\n",
      "      168    0.000    0.000    0.001    0.000 module.py:2645(named_parameters)\n",
      "     3136    0.001    0.000    0.001    0.000 {method 'join' of 'bytes' objects}\n",
      "       48    0.001    0.000    0.001    0.000 adam.py:745(<listcomp>)\n",
      "      168    0.000    0.000    0.001    0.000 module.py:2600(_named_members)\n",
      "       48    0.000    0.000    0.001    0.000 os.py:772(getenv)\n",
      "      588    0.000    0.000    0.001    0.000 __init__.py:38(__get__)\n",
      "      637    0.001    0.000    0.001    0.000 {built-in method torch._C._are_functorch_transforms_active}\n",
      "      244    0.001    0.000    0.001    0.000 typing.py:306(inner)\n",
      "       48    0.001    0.000    0.001    0.000 adam.py:747(<listcomp>)\n",
      "      566    0.000    0.000    0.001    0.000 module.py:2731(children)\n",
      "      174    0.000    0.000    0.001    0.000 abc.py:117(__instancecheck__)\n",
      "      381    0.001    0.000    0.001    0.000 grad_mode.py:75(__init__)\n",
      "      207    0.000    0.000    0.001    0.000 threading.py:1169(is_alive)\n",
      "       48    0.000    0.000    0.001    0.000 _collections_abc.py:821(get)\n",
      "      633    0.000    0.000    0.001    0.000 parameter.py:216(__instancecheck__)\n",
      "      100    0.000    0.000    0.001    0.000 {method 'format' of 'str' objects}\n",
      "      858    0.001    0.000    0.001    0.000 {built-in method torch._C._set_grad_enabled}\n",
      "       12    0.000    0.000    0.001    0.000 einops.py:603(repeat)\n",
      "      100    0.000    0.000    0.001    0.000 utils.py:273(_is_ascii)\n",
      "       48    0.000    0.000    0.001    0.000 graphs.py:25(is_current_stream_capturing)\n",
      "       12    0.000    0.000    0.001    0.000 normalization.py:210(reset_parameters)\n",
      "       52    0.000    0.000    0.001    0.000 threading.py:545(__init__)\n",
      "       48    0.000    0.000    0.001    0.000 _contextlib.py:146(clone)\n",
      "       99    0.001    0.000    0.001    0.000 std.py:400(format_interval)\n",
      "      174    0.000    0.000    0.001    0.000 {built-in method _abc._abc_instancecheck}\n",
      "      146    0.000    0.000    0.001    0.000 _pytree.py:603(_dict_flatten)\n",
      "        1    0.000    0.000    0.001    0.001 std.py:438(status_printer)\n",
      "       48    0.001    0.000    0.001    0.000 {built-in method torch._C._cuda_isCurrentStreamCapturing}\n",
      "     1816    0.001    0.000    0.001    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "       49    0.001    0.000    0.001    0.000 {built-in method torch.zeros}\n",
      "       49    0.000    0.000    0.000    0.000 os.py:675(__getitem__)\n",
      "      381    0.000    0.000    0.000    0.000 _contextlib.py:154(__new__)\n",
      "      146    0.000    0.000    0.000    0.000 _ops.py:1037(<lambda>)\n",
      "       77    0.000    0.000    0.000    0.000 init.py:446(_calculate_correct_fan)\n",
      "      566    0.000    0.000    0.000    0.000 module.py:2740(named_children)\n",
      "      118    0.000    0.000    0.000    0.000 init.py:345(_calculate_fan_in_and_fan_out)\n",
      "       50    0.000    0.000    0.000    0.000 std.py:1446(format_dict)\n",
      "       52    0.000    0.000    0.000    0.000 threading.py:236(__init__)\n",
      "      289    0.000    0.000    0.000    0.000 std.py:231(__call__)\n",
      "     1415    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C.TensorBase' objects}\n",
      "       49    0.000    0.000    0.000    0.000 {method 'unsqueeze' of 'torch._C.TensorBase' objects}\n",
      "     2382    0.000    0.000    0.000    0.000 {built-in method unicodedata.east_asian_width}\n",
      "  993/143    0.000    0.000    0.000    0.000 module.py:2787(named_modules)\n",
      "      588    0.000    0.000    0.000    0.000 function.py:35(save_for_backward)\n",
      "       53    0.000    0.000    0.000    0.000 std.py:102(acquire)\n",
      "     1287    0.000    0.000    0.000    0.000 {built-in method torch.is_grad_enabled}\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:1003(add_param_group)\n",
      "      767    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_variadic}\n",
      "       12    0.000    0.000    0.000    0.000 init.py:245(ones_)\n",
      "      588    0.000    0.000    0.000    0.000 function.py:592(_is_setup_context_defined)\n",
      "      167    0.000    0.000    0.000    0.000 module.py:917(compute_should_use_set_data)\n",
      "       12    0.000    0.000    0.000    0.000 init.py:62(_no_grad_fill_)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:333(_screen_shape_linux)\n",
      "       12    0.000    0.000    0.000    0.000 _backends.py:263(add_axes)\n",
      "      207    0.000    0.000    0.000    0.000 threading.py:1102(_wait_for_tstate_lock)\n",
      "      588    0.000    0.000    0.000    0.000 {built-in method torch._C._get_cudnn_enabled}\n",
      "       77    0.000    0.000    0.000    0.000 init.py:72(calculate_gain)\n",
      "      100    0.000    0.000    0.000    0.000 eval_frame.py:126(_maybe_set_eval_frame)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method fcntl.ioctl}\n",
      "       50    0.000    0.000    0.000    0.000 std.py:186(__format__)\n",
      "        7    0.000    0.000    0.000    0.000 container.py:110(__init__)\n",
      "       49    0.000    0.000    0.000    0.000 container.py:344(__iter__)\n",
      "       61    0.000    0.000    0.000    0.000 abc.py:121(__subclasscheck__)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:480(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:419(_get_iterator)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:766(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 ipkernel.py:775(_clean_thread_parent_frames)\n",
      "       49    0.000    0.000    0.000    0.000 {built-in method now}\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:634(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 activation.py:427(__init__)\n",
      "      598    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "       48    0.000    0.000    0.000    0.000 _foreach_utils.py:12(_get_fused_kernels_supported_devices)\n",
      "       53    0.000    0.000    0.000    0.000 std.py:106(release)\n",
      "      292    0.000    0.000    0.000    0.000 _pytree.py:575(_tuple_flatten)\n",
      "      155    0.000    0.000    0.000    0.000 iostream.py:138(_event_pipe)\n",
      "       50    0.000    0.000    0.000    0.000 std.py:153(__init__)\n",
      "       49    0.000    0.000    0.000    0.000 os.py:755(encode)\n",
      "       61    0.000    0.000    0.000    0.000 {built-in method _abc._abc_subclasscheck}\n",
      "       52    0.000    0.000    0.000    0.000 iostream.py:550(_is_master_process)\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method torch.rand}\n",
      "       12    0.000    0.000    0.000    0.000 init.py:258(zeros_)\n",
      "      443    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method torch.expm1}\n",
      "     1380    0.000    0.000    0.000    0.000 {function _ParameterMeta.__instancecheck__ at 0x7f484a3a6a70}\n",
      "      281    0.000    0.000    0.000    0.000 module.py:1945(remove_from)\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method torch.ones}\n",
      "       49    0.000    0.000    0.000    0.000 __init__.py:1710(getEffectiveLevel)\n",
      "       12    0.000    0.000    0.000    0.000 init.py:67(_no_grad_zero_)\n",
      "     1050    0.000    0.000    0.000    0.000 {built-in method builtins.ord}\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method torch.arange}\n",
      "       60    0.000    0.000    0.000    0.000 utils.py:11(parse)\n",
      "       50    0.000    0.000    0.000    0.000 {method 'sub' of 're.Pattern' objects}\n",
      "        6    0.000    0.000    0.000    0.000 activation.py:729(__init__)\n",
      "      158    0.000    0.000    0.000    0.000 threading.py:1145(ident)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'fill_' of 'torch._C.TensorBase' objects}\n",
      "       12    0.000    0.000    0.000    0.000 _backends.py:276(add_axis)\n",
      "      594    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "      167    0.000    0.000    0.000    0.000 {built-in method torch._has_compatible_shallow_copy_type}\n",
      "      236    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'random_' of 'torch._C.TensorBase' objects}\n",
      "       27    0.000    0.000    0.000    0.000 module.py:624(add_module)\n",
      "      167    0.000    0.000    0.000    0.000 _python_dispatch.py:369(is_traceable_wrapper_subclass)\n",
      "      165    0.000    0.000    0.000    0.000 optimizer.py:209(_get_scalar_dtype)\n",
      "       50    0.000    0.000    0.000    0.000 eval_frame.py:262(_is_skip_guard_eval_unsafe_stance)\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method torch.unsqueeze}\n",
      "       52    0.000    0.000    0.000    0.000 iostream.py:505(parent_header)\n",
      "      501    0.000    0.000    0.000    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "       48    0.000    0.000    0.000    0.000 __init__.py:152(_is_compiled)\n",
      "       96    0.000    0.000    0.000    0.000 {built-in method torch._C._get_privateuse1_backend_name}\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1286(fp_write)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'clamp' of 'torch._C.TensorBase' objects}\n",
      "        6    0.000    0.000    0.000    0.000 ipkernel.py:790(<setcomp>)\n",
      "       52    0.000    0.000    0.000    0.000 threading.py:1430(current_thread)\n",
      "      200    0.000    0.000    0.000    0.000 {built-in method torch._C._dynamo.eval_frame.set_eval_frame}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'expand' of 'torch._C.TensorBase' objects}\n",
      "       49    0.000    0.000    0.000    0.000 {built-in method builtins.round}\n",
      "      382    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x742500}\n",
      "       50    0.000    0.000    0.000    0.000 eval_frame.py:179(_callback_from_stance)\n",
      "       52    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "      349    0.000    0.000    0.000    0.000 {built-in method math.sqrt}\n",
      "        1    0.000    0.000    0.000    0.000 std.py:686(_decr_instances)\n",
      "       49    0.000    0.000    0.000    0.000 overrides.py:1962(is_tensor_like)\n",
      "       49    0.000    0.000    0.000    0.000 _reduction.py:8(get_enum)\n",
      "       12    0.000    0.000    0.000    0.000 {method 'copy_' of 'torch._C.TensorBase' objects}\n",
      "       50    0.000    0.000    0.000    0.000 utils.py:108(__init__)\n",
      "       12    0.000    0.000    0.000    0.000 utils.py:26(_reverse_repeat_tuple)\n",
      "       52    0.000    0.000    0.000    0.000 threading.py:264(__enter__)\n",
      "       49    0.000    0.000    0.000    0.000 3962538750.py:71(<listcomp>)\n",
      "      248    0.000    0.000    0.000    0.000 {built-in method builtins.divmod}\n",
      "       48    0.000    0.000    0.000    0.000 optimizer.py:97(_stack_if_compiling)\n",
      "       53    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.RLock' objects}\n",
      "       50    0.000    0.000    0.000    0.000 {method 'encode' of 'str' objects}\n",
      "        1    0.000    0.000    0.000    0.000 loss.py:1283(__init__)\n",
      "      142    0.000    0.000    0.000    0.000 module.py:2670(<lambda>)\n",
      "       53    0.000    0.000    0.000    0.000 {method 'acquire' of '_multiprocessing.SemLock' objects}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'zero_' of 'torch._C.TensorBase' objects}\n",
      "       49    0.000    0.000    0.000    0.000 {method 'numel' of 'torch._C.TensorBase' objects}\n",
      "      194    0.000    0.000    0.000    0.000 {built-in method time.time}\n",
      "      170    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "       49    0.000    0.000    0.000    0.000 _collections_abc.py:315(__subclasshook__)\n",
      "       48    0.000    0.000    0.000    0.000 {built-in method torch._C._cuda_getDeviceCount}\n",
      "       52    0.000    0.000    0.000    0.000 threading.py:267(__exit__)\n",
      "        6    0.000    0.000    0.000    0.000 threading.py:1478(enumerate)\n",
      "       48    0.000    0.000    0.000    0.000 _foreach_utils.py:8(_get_foreach_kernels_supported_devices)\n",
      "       49    0.000    0.000    0.000    0.000 __init__.py:233(_tensor_or_tensors_to_tuple)\n",
      "      146    0.000    0.000    0.000    0.000 __init__.py:129(annotate)\n",
      "       52    0.000    0.000    0.000    0.000 threading.py:279(_is_owned)\n",
      "        1    0.000    0.000    0.000    0.000 loss.py:50(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 container.py:297(__init__)\n",
      "       48    0.000    0.000    0.000    0.000 __init__.py:39(is_built)\n",
      "       52    0.000    0.000    0.000    0.000 threading.py:276(_acquire_restore)\n",
      "      104    0.000    0.000    0.000    0.000 {built-in method _thread.allocate_lock}\n",
      "      208    0.000    0.000    0.000    0.000 threading.py:553(is_set)\n",
      "       50    0.000    0.000    0.000    0.000 {method 'update' of 'dict' objects}\n",
      "      146    0.000    0.000    0.000    0.000 {method '__exit__' of 'torch._C.DisableTorchFunctionSubclass' objects}\n",
      "       52    0.000    0.000    0.000    0.000 threading.py:273(_release_save)\n",
      "       96    0.000    0.000    0.000    0.000 decorators.py:261(graph_break)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:663(__new__)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:511(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 container.py:348(__iadd__)\n",
      "      207    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "        1    0.000    0.000    0.000    0.000 container.py:420(extend)\n",
      "        3    0.000    0.000    0.000    0.000 _weakrefset.py:63(__iter__)\n",
      "       50    0.000    0.000    0.000    0.000 utils.py:112(__format__)\n",
      "       50    0.000    0.000    0.000    0.000 std.py:167(colour)\n",
      "        1    0.000    0.000    0.000    0.000 loss.py:41(__init__)\n",
      "        3    0.000    0.000    0.000    0.000 mnist.py:153(__len__)\n",
      "        4    0.000    0.000    0.000    0.000 std.py:110(__enter__)\n",
      "      100    0.000    0.000    0.000    0.000 _utils_internal.py:172(justknobs_check)\n",
      "      100    0.000    0.000    0.000    0.000 {built-in method torch._C._dynamo.eval_frame.set_skip_guard_eval_unsafe}\n",
      "       53    0.000    0.000    0.000    0.000 {method 'release' of '_multiprocessing.SemLock' objects}\n",
      "       49    0.000    0.000    0.000    0.000 worker.py:101(get_worker_info)\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:340(__len__)\n",
      "        2    0.000    0.000    0.000    0.000 sampler.py:160(num_samples)\n",
      "      167    0.000    0.000    0.000    0.000 __future__.py:25(get_overwrite_module_params_on_conversion)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:679(_get_free_pos)\n",
      "       52    0.000    0.000    0.000    0.000 {method 'write' of '_io.StringIO' objects}\n",
      "       36    0.000    0.000    0.000    0.000 utils.py:32(<genexpr>)\n",
      "       58    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.RLock' objects}\n",
      "      142    0.000    0.000    0.000    0.000 __future__.py:68(get_swap_module_params_on_conversion)\n",
      "        1    0.000    0.000    0.000    0.000 sampler.py:194(__len__)\n",
      "        3    0.000    0.000    0.000    0.000 _tensor.py:1159(__len__)\n",
      "        4    0.000    0.000    0.000    0.000 std.py:113(__exit__)\n",
      "       50    0.000    0.000    0.000    0.000 std.py:163(colour)\n",
      "       52    0.000    0.000    0.000    0.000 {built-in method builtins.abs}\n",
      "        1    0.000    0.000    0.000    0.000 _weakrefset.py:111(remove)\n",
      "       77    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
      "       36    0.000    0.000    0.000    0.000 {built-in method math.log}\n",
      "       52    0.000    0.000    0.000    0.000 {method 'get' of '_contextvars.ContextVar' objects}\n",
      "        1    0.000    0.000    0.000    0.000 std.py:682(<setcomp>)\n",
      "       52    0.000    0.000    0.000    0.000 {built-in method _thread.get_ident}\n",
      "       48    0.000    0.000    0.000    0.000 optimizer.py:451(_optimizer_step_code)\n",
      "        3    0.000    0.000    0.000    0.000 {method 'remove' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 module.py:512(register_buffer)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:98(_get_distributed_settings)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:213(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:27(__exit__)\n",
      "       52    0.000    0.000    0.000    0.000 {method '__enter__' of '_thread.lock' objects}\n",
      "       53    0.000    0.000    0.000    0.000 {method 'release' of '_thread.RLock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:347(<listcomp>)\n",
      "       52    0.000    0.000    0.000    0.000 {method '__exit__' of '_thread.lock' objects}\n",
      "       52    0.000    0.000    0.000    0.000 {method 'release' of '_thread.lock' objects}\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:1269(is_initialized)\n",
      "        1    0.000    0.000    0.000    0.000 optimizer.py:516(_patch_step_function)\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:53(_commit_removals)\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method math.ceil}\n",
      "        1    0.000    0.000    0.000    0.000 functools.py:393(__get__)\n",
      "        1    0.000    0.000    0.000    0.000 dataloader.py:75(create_fetcher)\n",
      "        1    0.000    0.000    0.000    0.000 _weakrefset.py:86(add)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:266(_supports_unicode)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method fromtimestamp}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._nn._parse_to}\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:21(__enter__)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:125(__eq__)\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:721(WORLD)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:187(disable_on_exception)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:156(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'manual_seed' of 'torch._C.Generator' objects}\n",
      "        3    0.000    0.000    0.000    0.000 utils.py:152(wrapper_setattr)\n",
      "        2    0.000    0.000    0.000    0.000 dataloader.py:499(_index_sampler)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1157(__hash__)\n",
      "        2    0.000    0.000    0.000    0.000 std.py:1153(_comparable)\n",
      "       11    0.000    0.000    0.000    0.000 {method 'setdefault' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 __init__.py:14(is_available)\n",
      "        1    0.000    0.000    0.000    0.000 _monitor.py:94(report)\n",
      "        2    0.000    0.000    0.000    0.000 _weakrefset.py:17(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:139(__getattr__)\n",
      "        1    0.000    0.000    0.000    0.000 fetch.py:9(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 utils.py:222(__eq__)\n",
      "        3    0.000    0.000    0.000    0.000 std.py:226(__init__)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:760(get_lock)\n",
      "        1    0.000    0.000    0.000    0.000 distributed_c10d.py:596(default_pg)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 iostream.py:364(fileno)\n",
      "        3    0.000    0.000    0.000    0.000 dataloader.py:495(_auto_collation)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:252(_is_utf)\n",
      "        1    0.000    0.000    0.000    0.000 std.py:1147(__del__)\n",
      "        1    0.000    0.000    0.000    0.000 container.py:340(__len__)\n",
      "        1    0.000    0.000    0.000    0.000 utils.py:282(_screen_shape_wrapper)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method _weakref.proxy}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'discard' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.min}\n",
      "        1    0.000    0.000    0.000    0.000 tz.py:74(utcoffset)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'difference' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'isdisjoint' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 std.py:1301(<lambda>)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcProfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain()\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcumtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/Storage/tbalasoor/persistent/mambaenv/lib/python3.10/cProfile.py:17\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(statement, filename, sort)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(statement, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pyprofile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Utils\u001b[49m\u001b[43m(\u001b[49m\u001b[43mProfile\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/Storage/tbalasoor/persistent/mambaenv/lib/python3.10/profile.py:54\u001b[0m, in \u001b[0;36m_Utils.run\u001b[0;34m(self, statement, filename, sort)\u001b[0m\n\u001b[1;32m     52\u001b[0m prof \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler()\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[43mprof\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSystemExit\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/Storage/tbalasoor/persistent/mambaenv/lib/python3.10/cProfile.py:96\u001b[0m, in \u001b[0;36mProfile.run\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m__main__\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m __main__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\n\u001b[0;32m---> 96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunctx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/Storage/tbalasoor/persistent/mambaenv/lib/python3.10/cProfile.py:101\u001b[0m, in \u001b[0;36mProfile.runctx\u001b[0;34m(self, cmd, globals, locals)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable()\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "Cell \u001b[0;32mIn[15], line 23\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(preds, labels)\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 23\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     26\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/workspace/Storage/tbalasoor/persistent/mambaenv/lib/python3.10/site-packages/torch/_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/Storage/tbalasoor/persistent/mambaenv/lib/python3.10/site-packages/torch/autograd/__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/Storage/tbalasoor/persistent/mambaenv/lib/python3.10/site-packages/torch/autograd/graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cProfile.run('train()', sort='cumtime')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mambakernel",
   "language": "python",
   "name": "mambakernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
